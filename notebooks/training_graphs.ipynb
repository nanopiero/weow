{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Targets used to train WEOW models\n",
        "# (notebook still under construction)"
      ],
      "metadata": {
        "id": "kJQBNrMGsqD_"
      },
      "id": "kJQBNrMGsqD_"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f95d9a2d-5843-4f86-a56c-ea5a12c3097b",
      "metadata": {
        "id": "f95d9a2d-5843-4f86-a56c-ea5a12c3097b"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from os.path import join, isdir, isfile\n",
        "from os import listdir as ls\n",
        "import os\n",
        "import pickle\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import torch\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get models and images\n",
        "! pip install huggingface_hub\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "xZg8RH3CETfa"
      },
      "id": "xZg8RH3CETfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Download a directed graphs (DG)...\n",
        "file_path = 'weow_semi_supervision_training_DG.pkl'\n",
        "dgs_path =  hf_hub_download(repo_id=\"nanopiero/weow_training_graphs\",\n",
        "                            filename=file_path,\n",
        "                            repo_type=\"dataset\"\n",
        "                            )\n",
        "# ...an untransitive undirected graphs (UG)...\n",
        "file_path = 'weow_semi_supervision_training_UG.pkl'\n",
        "ugs_path =  hf_hub_download(repo_id=\"nanopiero/weow_training_graphs\",\n",
        "                            filename=file_path,\n",
        "                            repo_type=\"dataset\"\n",
        "                            )"
      ],
      "metadata": {
        "id": "j5mWc3YMP2xR"
      },
      "id": "j5mWc3YMP2xR",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in case of timeout: turn on the option High-RAM (Runtime/change runtime type)\n",
        "# - the loading should take less than 10 sec\n",
        "with open(dgs_path, 'rb') as file:\n",
        "  dgs = pickle.load(file)"
      ],
      "metadata": {
        "id": "_g6zUmVgpC5g"
      },
      "id": "_g6zUmVgpC5g",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dgs contains three sets of targets, 'train', 'vali' (for Validation Intra,\n",
        "# ie images coming from the train cameras, but unseen pairs, and for Validation\n",
        "# Extra, ie images coming from independant cameras)\n",
        "dgs.keys()"
      ],
      "metadata": {
        "id": "wStKbL8dER8x"
      },
      "id": "wStKbL8dER8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handcrafted strict ordered training pairs are contained in the first element of the list:\n",
        "dg_handcrafted = dgs['train'][0]\n",
        "\n",
        "# This first element is a graph, the nodes of which are images\n",
        "print(len(dg_handcrafted.nodes)) # 34726\n",
        "\n",
        "# The image names are strucured as cameraID_YYYYMMDD_HHMMSS. For example:\n",
        "print(list(dg_handcrafted.nodes)[1000]) # 13853_20110220_220111.jpg\n",
        "\n",
        "# Most of the cameraID refer to the AMOS directory, where images could be found\n",
        "# but some images (3769) are coming from other webcam archives. In this case,\n",
        "# the cameraID is not a number:\n",
        "print(len([n for n in list(dg_handcrafted.nodes) if not n.split('_')[0].isdigit()]))\n",
        "\n",
        "# Some of the images/edges have been fully labeled.\n",
        "# As labelling involved several steps with a more or less deep image-wise annotation,\n",
        "# The images are diversely annotated:\n",
        "print(dg_handcrafted.nodes['13853_20110220_220111.jpg'])\n",
        "\n",
        "# In this case, it gives a dense annoation :\n",
        "# 'cam': id of the AMOS repository (with or without the 000 prefix)\n",
        "# 'snowfall': if snow is falling\n",
        "# 'rd_features': specific road features (eg drifts on the road)\n",
        "# 'atmo': how is the weather from the image\n",
        "# 'noise': 'no', if there are artefacts, hardprinted letters etc\n",
        "# 'mask': 'droplets', if there are meteorological masks (snowflake or droplets)\n",
        "# 'time': lighting conditions\n",
        "# 'ground': level of the snow cover\n",
        "# 'visi': comparison with the previous image wrt vibility\n",
        "# 'old snow_traces': presence of remaining neves\n",
        "# 'plus_snow': '',\n",
        "# 'compa': comparison with the rpevious image wrt snow-cover\n",
        "# 'sequence': 287, id of the homogenenous sequence\n",
        "# 'vv' : measured visibility (if a colocalized visibilimeter is available. -1 if not.)\n",
        "\n",
        "# second example:\n",
        "print(dg_handcrafted.nodes['00010103_4_20170103_093352.jpg'])\n",
        "# It gives :\n",
        "# 'sequence': id of the homogeneous sequence\n",
        "# 'levelvv': rank of the image in a manually sorted batch of five images\n",
        "\n",
        "# For some edges of this directed graph, a weight has been given, eg:\n",
        "print(dg_handcrafted.edges[('1002_20080117_140759.jpg', '1002_20080117_153753.jpg')])\n",
        "print(dg_handcrafted.edges[('00010722_3_20170430_184302.jpg', '00010722_3_20150917_144251.jpg')])\n",
        "# These edges have been labelled manually with a high degree of certainty\n",
        "# (weight = 0 and weight = 1 correspond to two different annotation methods)\n",
        "# The other edges could have been obtained either by transitivity or by a\n",
        "# a lower-quality process of comparison.\n",
        "\n",
        "# The other sets ('vali' and 'vale') are structured as dg_handcrafted"
      ],
      "metadata": {
        "id": "5ZXAaBP5sVcg"
      },
      "id": "5ZXAaBP5sVcg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Other strictly ordered pairs have been obtained automatically\n",
        "# thanks to an accessory classifier:\n",
        "automatic_edges = dgs['train'][1]\n",
        "# as there is no supplementary labels, these edges were simply listed:\n",
        "print(len(automatic_edges))\n",
        "# here, the image names are formatted on \"amosRepoId_sequenceId_YYYYMMDD_HHMMSS\"\n",
        "# sequenceId refer to an homogeneous sequence of images of the AMOS Repo.\n",
        "# For example:\n",
        "print(automatic_edges[0][0])"
      ],
      "metadata": {
        "id": "LH8H7OLCdLTH"
      },
      "id": "LH8H7OLCdLTH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The second hf dataset represent incomparable pairs of images\n",
        "# with open(ugs_path, 'rb') as file:\n",
        "#   ugs = pickle.load(file)\n",
        "\n",
        "# The structure of ugs is the same as the structure of dgs:\n",
        "print(ugs.keys())\n",
        "\n",
        "# However, there is two handcrafted sets:\n",
        "ug_handcrafted = ugs['train'][0]\n",
        "print(len(ug_handcrafted.nodes))\n",
        "\n",
        "ug_with_noise_only = ugs['train'][1]\n",
        "print(len(ug_with_noise_only.nodes))\n",
        "\n",
        "# the second graph contain incomparability with images\n",
        "# that tell nothing (directly) about snow-cover or haze\n",
        "\n",
        "# Moover, the supplementary image-wise labels are lighter:\n",
        "print(ug_handcrafted.nodes['32841_20170427_104304.jpg'])\n",
        "# But the edges are annotated with type of incomparability (\"toi\"):\n",
        "print(ug_handcrafted.edges[('2030_20121219_211528.jpg', '2030_20121220_164531.jpg')])\n",
        "# It specifies, if possible, the relative positions of the output intervals Ix = [xinf, xsup] and\n",
        "# Iy = [yinf, ysup] that should be associated with the first and second image.\n",
        "# For example: -1, 1, -1, -1 means xinf > yinf ; xinf < ysup ; xsup > yinf ; xsup > ysup\n",
        "# the second graphs only contain inclusions:\n",
        "for i in range(10000,10005):\n",
        "  print(list(ug_with_noise_only.edges)[i], ug_with_noise_only.edges[list(ug_with_noise_only.edges)[i]])\n",
        "# the weight \"2\" helps ot distinguish these edges from those of ug_handcrafted in case of union\n",
        "\n",
        "# Please note that, despite the name ug, which suggest that the graphs\n",
        "# are undirected, the underlying structure is a directed graph.\n",
        "print(ug_with_noise_only, ug_handcrafted)\n",
        "\n",
        "# This is because the interpretation of the toi depends on how the image pair is ordered.\n",
        "# For example, [1, 1, -1, -1] for (Image x, Image y) means Ix should includes Iy\n",
        "# but it means Ix is included in Iy for (Image y, Image x)."
      ],
      "metadata": {
        "id": "KAt-bd65EKZZ"
      },
      "id": "KAt-bd65EKZZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fainally other incomparable pairs have also been obtained automatically\n",
        "# thanks to the previously quoted accessory classifier:\n",
        "automatic_edges = ugs['train'][2]\n",
        "print(len(automatic_edges))\n",
        "# here, the image names are formatted on \"amosRepoId_sequenceId_YYYYMMDD_HHMMSS\"\n",
        "# sequenceId refer to an homogeneous sequence of images of the AMOS Repo.\n",
        "# For these pairs, toi are not defined:\n",
        "print(automatic_edges[0])"
      ],
      "metadata": {
        "id": "j6sTL3p3IzhI",
        "outputId": "84879094-bbcb-42c4-b34b-ccfdb1d1d62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "j6sTL3p3IzhI",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23165147\n",
            "('00010101_0_20100317_170906.jpg', '00010101_0_20101031_142130.jpg')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}