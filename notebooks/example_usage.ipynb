{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f95d9a2d-5843-4f86-a56c-ea5a12c3097b",
      "metadata": {
        "id": "f95d9a2d-5843-4f86-a56c-ea5a12c3097b"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "from os.path import join, isdir, isfile\n",
        "from os import listdir as ls\n",
        "import copy\n",
        "import os\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, widgets\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Local clone\n",
        "! git clone https://github.com/nanopiero/weow.git\n",
        "import sys\n",
        "sys.path.append('weow')\n",
        "from src.utils import *"
      ],
      "metadata": {
        "id": "Lz52xvY0FPoz"
      },
      "id": "Lz52xvY0FPoz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To get models and images\n",
        "! pip install huggingface_hub\n",
        "from huggingface_hub import hf_hub_download"
      ],
      "metadata": {
        "id": "xZg8RH3CETfa"
      },
      "id": "xZg8RH3CETfa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Step 1: Download the zip file using hf_hub_download\n",
        "local_zip = hf_hub_download(repo_id=\"nanopiero/weow\", filename=\"webcam_images.zip\")\n",
        "\n",
        "# Step 2: Unzip the contents\n",
        "with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall('webcam_images')"
      ],
      "metadata": {
        "id": "OZ_AK8gFTAkx"
      },
      "id": "OZ_AK8gFTAkx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all .jpg images in the directory\n",
        "image_dir = 'webcam_images'\n",
        "image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.jpg')], key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "def show_image(index):\n",
        "    img_path = os.path.join('webcam_images', image_files[index])\n",
        "    img = Image.open(img_path)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')  # Hide axes\n",
        "    plt.show()\n",
        "\n",
        "# Use a slider to scroll through the images\n",
        "interact(show_image, index=widgets.IntSlider(min=0, max=len(image_files)-1, step=1, description=\"Image Index\"));\n"
      ],
      "metadata": {
        "id": "tYNFFyQmH1Ji"
      },
      "id": "tYNFFyQmH1Ji",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting with respect to Horizontal Visibility"
      ],
      "metadata": {
        "id": "oPVWMeUBsXcE"
      },
      "id": "oPVWMeUBsXcE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and Load the Models from Hugging Face\n",
        "\n",
        "# List of models to download and use\n",
        "model_names = [\n",
        "        'vv_sl_2024_fss_1.checkpoint',\n",
        "        'vv_sl_2024_fss_2.checkpoint',\n",
        "        'vv_sl_2024_iss_1.checkpoint' ,\n",
        "        'vv_sl_2024_iss_2.checkpoint',\n",
        "]\n",
        "\n",
        "# Step 2: Initialize the Transformation and Load the Dataset\n",
        "\n",
        "# Configuration for Simple_crop transformation\n",
        "marginsup = 0.0\n",
        "margininf = 0.0\n",
        "cropped_prop = 1.0\n",
        "size_in = 256 + 32\n",
        "size_out = 256 - 32\n",
        "\n",
        "# Instantiate the transformation\n",
        "tr = Simple_crop(marginsup, margininf, cropped_prop, size_in, size_out)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "image_dir = 'webcam_images'\n",
        "dataset = WebcamImagesDataset(image_dir=image_dir, transform=tr)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Step 3: Load Models onto GPU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "models = [load_model(model_name) for model_name in model_names]\n",
        "\n",
        "# Step 4: Perform Inference\n",
        "mean_outputs = []\n",
        "\n",
        "for images in dataloader:\n",
        "    images = images.to(device)\n",
        "    outputs = []\n",
        "\n",
        "    # Run the image through each model and collect outputs\n",
        "    for k, model in enumerate(models):\n",
        "        with torch.no_grad():\n",
        "            output = model(images)[0]\n",
        "            if 'rev' in model_names[k]:\n",
        "              output *= -1\n",
        "            outputs.append(output)\n",
        "\n",
        "    # Compute the mean of the outputs across models\n",
        "    mean_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "    mean_outputs.append(mean_output.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "rjLkdBF-sf47"
      },
      "id": "rjLkdBF-sf47",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting with respect to snow cover"
      ],
      "metadata": {
        "id": "GaesIGGBFTvC"
      },
      "id": "GaesIGGBFTvC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Download and Load the Models from Hugging Face\n",
        "\n",
        "# List of models to download and use\n",
        "model_names = [\n",
        "        'ss_sl_rev_due222.0.pth',\n",
        "        'ss_sl_rev_due222.1.pth',\n",
        "        'ss_sl_due222.0.pth' ,\n",
        "        'ss_sl_du22.0.pth',\n",
        "        'ss_sl_due222.1.pth',\n",
        "]\n",
        "\n",
        "# Step 2: Initialize the Transformation and Load the Dataset\n",
        "\n",
        "# Configuration for Simple_crop transformation\n",
        "marginsup = 0.0\n",
        "margininf = 0.0\n",
        "cropped_prop = 1.0\n",
        "size_in = 256 + 32\n",
        "size_out = 256 - 32\n",
        "\n",
        "# Instantiate the transformation\n",
        "tr = Simple_crop(marginsup, margininf, cropped_prop, size_in, size_out)\n",
        "\n",
        "# Create dataset and dataloader\n",
        "image_dir = 'webcam_images'\n",
        "dataset = WebcamImagesDataset(image_dir=image_dir, transform=tr)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Step 3: Load Models onto GPU\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "models = [load_model(model_name) for model_name in model_names]\n",
        "\n",
        "# Step 4: Perform Inference\n",
        "mean_outputs = []\n",
        "\n",
        "for images in dataloader:\n",
        "    images = images.to(device)\n",
        "    outputs = []\n",
        "\n",
        "    # Run the image through each model and collect outputs\n",
        "    for k, model in enumerate(models):\n",
        "        with torch.no_grad():\n",
        "            output = model(images)[0]\n",
        "            if 'rev' in model_names[k]:\n",
        "              output *= -1\n",
        "            outputs.append(output)\n",
        "\n",
        "    # Compute the mean of the outputs across models\n",
        "    mean_output = torch.mean(torch.stack(outputs), dim=0)\n",
        "    mean_outputs.append(mean_output.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "mn7lso6HIPfZ"
      },
      "id": "mn7lso6HIPfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "Gk_cugTxs3yA"
      },
      "id": "Gk_cugTxs3yA"
    },
    {
      "cell_type": "code",
      "source": [
        "# To plot output interval\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "!pip install bqplot\n",
        "import bqplot as bq\n",
        "from ipywidgets import HBox, Output, interact, IntSlider\n",
        "\n",
        "def display_image(image_path):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)  # Clear previous output\n",
        "        img = Image.open(image_path)  # Load the image\n",
        "        img = img.resize((int(img.width * 0.5), int(img.height * 0.5)))  # Resize the image by 50%\n",
        "        display(img)  # Display the resized image using IPython.display\n",
        "\n",
        "def show_image_from_index(index):\n",
        "    # Create a new color list and update all intervals\n",
        "    new_colors = ['gray'] * len(images)  # Reset all intervals to gray\n",
        "    new_colors[index] = 'red'  # Highlight the selected interval in red\n",
        "    lines.colors = new_colors  # Assign the new color list to the lines.colors trait\n",
        "\n",
        "    # Display the corresponding image\n",
        "    image_path = images[index]\n",
        "    display_image(image_path)"
      ],
      "metadata": {
        "id": "X9z7WhLsvcDR"
      },
      "id": "X9z7WhLsvcDR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intervals = mean_outputs\n",
        "image_files = sorted([ f for f in os.listdir(image_dir) \\\n",
        "                      if f.endswith('.jpg')], key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "images = [join(image_dir, f) for f in image_files]\n",
        "x_vals = list(range(len(images)))  # Corresponding indices for the intervals\n",
        "\n",
        "# Convert intervals using .item() to extract the values\n",
        "y_vals = [[interval[0, 0].item(), interval[0, 1].item()] for interval in intervals]\n",
        "\n",
        "# Step 1: Create the Output widget to display the image\n",
        "output = Output()\n",
        "\n",
        "# Step 2: Create the bqplot figure\n",
        "x_scale = bq.LinearScale()  # Change to LinearScale to spread the intervals evenly\n",
        "y_scale = bq.LinearScale()\n",
        "\n",
        "# Create the interval lines using the converted y_vals\n",
        "lines = bq.Lines(\n",
        "    x=[[x, x] for x in range(len(intervals))],  # X values are spread linearly\n",
        "    y=y_vals,  # Use the converted y values\n",
        "    scales={'x': x_scale, 'y': y_scale},\n",
        "    stroke_width=4,  # Narrower intervals (reduce width)\n",
        "    colors=['steelblue'] * len(intervals)  # Initial color for all intervals\n",
        ")\n",
        "\n",
        "# Step 3: Create the figure\n",
        "# We display one x-label for every 10 intervals and make them smaller to avoid overlap\n",
        "ax_x = bq.Axis(scale=x_scale, label='Index', tick_values=list(range(0, 211, 10)), tick_style={'font-size': 8})\n",
        "ax_y = bq.Axis(scale=y_scale, orientation='vertical', label='Interval')\n",
        "\n",
        "# Reduce the height of the plot by 40%\n",
        "fig = bq.Figure(marks=[lines], axes=[ax_x, ax_y], title='Intervals with Slider Control',\n",
        "                fig_margin={'top': 60, 'bottom': 50, 'left': 60, 'right': 50},\n",
        "                layout={'min_width': '1000px', 'min_height': '100px'})  # Reduce height by 40%\n",
        "\n",
        "# Step 4: Create the slider and connect it to the `show_image` function\n",
        "\n",
        "slider = IntSlider(\n",
        "    min=0,\n",
        "    max=209,  # Maximum value to match your x-axis\n",
        "    step=1,  # Step of 10 for the graduations\n",
        "    description=\"Image Index\",\n",
        "    layout={'width': '1000px'},  # Set slider width (length)\n",
        "    readout_format='d'  # Display integer format for readout\n",
        ")\n",
        "\n",
        "interact(show_image_from_index, index=slider)\n",
        "\n",
        "# Step 5: Display the HBox with the bqplot figure and Output widget side by side\n",
        "hbox = HBox([fig, output], layout={'width': '100%'})  # Set the layout to take full width\n",
        "display(hbox)\n"
      ],
      "metadata": {
        "id": "NjasVydnYxuX"
      },
      "id": "NjasVydnYxuX",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}